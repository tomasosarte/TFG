{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import optuna\n",
    "\n",
    "from environments.environment_tsp import EnviornmentTSP\n",
    "from networks.basic_network import BasicNetwork\n",
    "from params import default_params, set_tsp_params\n",
    "from experiments.actor_critic_experiment import ActorCriticExperiment\n",
    "from controllers.ac_controller import ActorCriticController\n",
    "from learners.reinforce_learner import ReinforceLearner\n",
    "from learners.biased_reinforce_learner import BiasedReinforceLearner\n",
    "from learners.off_policy_actor_critic_learner import OffpolicyActorCriticLearner\n",
    "from learners.ppo_learner import PPOLearner\n",
    "from generators.tsp_generator import TSPGenerator\n",
    "from exact_solvers.solver_tsp import solve_tsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_nodes_per_graph = 10\n",
    "instance = 0\n",
    "cities = th.load(f\"training/tsp/size_{max_nodes_per_graph}/instance_{instance}.pt\") \n",
    "tsp_generator = TSPGenerator()\n",
    "tsp_generator.plot_instance(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation: [0, 5, 3, 8, 7, 4, 6, 9, 1, 2]\n",
      "Distance: 2.9008774757385254\n"
     ]
    }
   ],
   "source": [
    "permutation, distance = solve_tsp(cities)\n",
    "print(f\"Permutation: {permutation}\\nDistance: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output masked: tensor([[ 0.0191,  0.0150, -0.0583, -0.0632,  0.0306,  0.0235, -0.0145, -0.1238,\n",
      "         -0.0895,  0.1178]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0.1032, 0.1027, 0.0955, 0.0950, 0.1044, 0.1036, 0.0998, 0.0894, 0.0925,\n",
      "         0.1139]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([False, False, False, False, False, False, False, False, False, False])\n",
      "Probs after: tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000]], grad_fn=<IndexPutBackward0>)\n",
      "--------------------------------------------------\n",
      "Output masked: tensor([[ 0.0079,  0.0070, -0.0544,    -inf,  0.0222,  0.0226, -0.0184, -0.1282,\n",
      "         -0.0975,  0.1212]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0.1132, 0.1131, 0.1064, 0.0000, 0.1148, 0.1149, 0.1102, 0.0988, 0.1019,\n",
      "         0.1268]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "         0.1111]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([False, False, False,  True, False, False, False, False, False, False])\n",
      "Probs after: tensor([[0.1111, 0.1111, 0.1111, 0.0000, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "         0.1111]], grad_fn=<IndexPutBackward0>)\n",
      "--------------------------------------------------\n",
      "Output masked: tensor([[ 0.0061,  0.0157, -0.0560,    -inf,  0.0279,  0.0291, -0.0213, -0.1232,\n",
      "            -inf,  0.1146]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0.1256, 0.1268, 0.1180, 0.0000, 0.1284, 0.1285, 0.1222, 0.1104, 0.0000,\n",
      "         0.1400]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "         0.1250]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([False, False, False,  True, False, False, False, False,  True, False])\n",
      "Probs after: tensor([[0.1250, 0.1250, 0.1250, 0.0000, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.1250]], grad_fn=<IndexPutBackward0>)\n",
      "--------------------------------------------------\n",
      "Output masked: tensor([[ 0.0011,  0.0189, -0.0510,    -inf,    -inf,  0.0318, -0.0196, -0.1169,\n",
      "            -inf,  0.1226]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0.1429, 0.1455, 0.1357, 0.0000, 0.0000, 0.1474, 0.1400, 0.1270, 0.0000,\n",
      "         0.1614]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.1429, 0.1429, 0.1429, 0.1428, 0.1428, 0.1429, 0.1429, 0.1429, 0.1428,\n",
      "         0.1429]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([False, False, False,  True,  True, False, False, False,  True, False])\n",
      "Probs after: tensor([[0.1429, 0.1429, 0.1429, 0.0000, 0.0000, 0.1429, 0.1429, 0.1429, 0.0000,\n",
      "         0.1429]], grad_fn=<IndexPutBackward0>)\n",
      "--------------------------------------------------\n",
      "Output masked: tensor([[ 0.0031,  0.0180, -0.0488,    -inf,    -inf,  0.0263, -0.0171,    -inf,\n",
      "            -inf,  0.1254]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0.1640, 0.1664, 0.1557, 0.0000, 0.0000, 0.1678, 0.1607, 0.0000, 0.0000,\n",
      "         0.1853]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.1667, 0.1667, 0.1667, 0.1666, 0.1666, 0.1667, 0.1667, 0.1666, 0.1666,\n",
      "         0.1667]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([False, False, False,  True,  True, False, False,  True,  True, False])\n",
      "Probs after: tensor([[0.1667, 0.1667, 0.1667, 0.0000, 0.0000, 0.1667, 0.1667, 0.0000, 0.0000,\n",
      "         0.1667]], grad_fn=<IndexPutBackward0>)\n",
      "--------------------------------------------------\n",
      "Output masked: tensor([[ 0.0045,  0.0162, -0.0624,    -inf,    -inf,  0.0262,    -inf,    -inf,\n",
      "            -inf,  0.1201]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0.1964, 0.1987, 0.1837, 0.0000, 0.0000, 0.2007, 0.0000, 0.0000, 0.0000,\n",
      "         0.2205]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "         0.2000]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([False, False, False,  True,  True, False,  True,  True,  True, False])\n",
      "Probs after: tensor([[0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2000]], grad_fn=<IndexPutBackward0>)\n",
      "--------------------------------------------------\n",
      "Output masked: tensor([[-0.0008,  0.0177, -0.0457,    -inf,    -inf,  0.0293,    -inf,    -inf,\n",
      "            -inf,    -inf]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0.2497, 0.2543, 0.2387, 0.0000, 0.0000, 0.2573, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "         0.2500]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([False, False, False,  True,  True, False,  True,  True,  True,  True])\n",
      "Probs after: tensor([[0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.2500, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]], grad_fn=<IndexPutBackward0>)\n",
      "--------------------------------------------------\n",
      "Output masked: tensor([[   -inf,  0.0329, -0.0596,    -inf,    -inf,  0.0285,    -inf,    -inf,\n",
      "            -inf,    -inf]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0.0000, 0.3440, 0.3136, 0.0000, 0.0000, 0.3424, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
      "         0.3333]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([ True, False, False,  True,  True, False,  True,  True,  True,  True])\n",
      "Probs after: tensor([[0.0000, 0.3333, 0.3333, 0.0000, 0.0000, 0.3333, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]], grad_fn=<IndexPutBackward0>)\n",
      "--------------------------------------------------\n",
      "Output masked: tensor([[  -inf, 0.0257,   -inf,   -inf,   -inf, 0.0288,   -inf,   -inf,   -inf,\n",
      "           -inf]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0.0000, 0.4992, 0.0000, 0.0000, 0.0000, 0.5008, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.4999, 0.5000, 0.4999, 0.4999, 0.4999, 0.5000, 0.4999, 0.4999, 0.4999,\n",
      "         0.4999]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([ True, False,  True,  True,  True, False,  True,  True,  True,  True])\n",
      "Probs after: tensor([[0.0000, 0.5000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]], grad_fn=<IndexPutBackward0>)\n",
      "--------------------------------------------------\n",
      "Output masked: tensor([[  -inf,   -inf,   -inf,   -inf,   -inf, 0.0355,   -inf,   -inf,   -inf,\n",
      "           -inf]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.9997, 0.9997, 0.9997, 0.9997, 0.9997, 1.0000, 0.9997, 0.9997, 0.9997,\n",
      "         0.9997]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([ True,  True,  True,  True,  True, False,  True,  True,  True,  True])\n",
      "Probs after: tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], grad_fn=<IndexPutBackward0>)\n",
      "--------------------------------------------------\n",
      "Output masked: tensor([[   -inf,    -inf,    -inf, -0.0467,    -inf,    -inf,    -inf,    -inf,\n",
      "            -inf,    -inf]], grad_fn=<MaskedFillBackward0>)\n",
      "Output probabilities: tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "-------------------\n",
      "Probs: tensor([[0.9997, 0.9997, 0.9997, 1.0000, 0.9997, 0.9997, 0.9997, 0.9997, 0.9997,\n",
      "         0.9997]], grad_fn=<AddBackward0>)\n",
      "Visited city tensor: tensor([True, True, True, True, True, True, True, True, True, True])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), None and long or byte Variables are valid indices (got float)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Run experiment\u001b[39;00m\n\u001b[1;32m     39\u001b[0m experiment \u001b[38;5;241m=\u001b[39m ActorCriticExperiment(params \u001b[38;5;241m=\u001b[39m params, model \u001b[38;5;241m=\u001b[39m basic_network, env \u001b[38;5;241m=\u001b[39m env, learner \u001b[38;5;241m=\u001b[39m learner)\n\u001b[0;32m---> 40\u001b[0m experiment\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/Desktop/TFG/code/experiments/actor_critic_experiment.py:65\u001b[0m, in \u001b[0;36mActorCriticExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m env_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_steps) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_steps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_episodes):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Run the policy fot batch_size steps\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, transition_buffer)\n\u001b[1;32m     66\u001b[0m     env_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv_steps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_length\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/TFG/code/runners/runner.py:103\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, n_steps, transition_buffer, trim, return_dict)\u001b[0m\n\u001b[1;32m    100\u001b[0m max_steps \u001b[38;5;241m=\u001b[39m n_steps \u001b[38;5;28;01mif\u001b[39;00m n_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepi_len\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# One step in the envionment\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontroller\u001b[38;5;241m.\u001b[39mchoose_action(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)\n\u001b[1;32m    104\u001b[0m     state, reward, done, next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m~/Desktop/TFG/code/controllers/epsilon_greedy_controller.py:72\u001b[0m, in \u001b[0;36mEpsilonGreedyController.choose_action\u001b[0;34m(self, state, increase_counter, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m increase_counter: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_decisions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# print(f\"State: {state[0][4:4+self.max_cities]}\")\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(f\"Probabilities:\\n {self.probabilities(state)}\")\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(probs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobabilities(state))\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/TFG/code/controllers/epsilon_greedy_controller.py:59\u001b[0m, in \u001b[0;36mEpsilonGreedyController.probabilities\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m probs\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     58\u001b[0m     first_city \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 59\u001b[0m     probs[first_city] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbs after: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprobs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), None and long or byte Variables are valid indices (got float)"
     ]
    }
   ],
   "source": [
    "# Get params\n",
    "params = default_params()\n",
    "\n",
    "rollouts_per_batch = 10\n",
    "pct_epsilon_anneal_time = 0.7\n",
    "embedding_dimension = 4\n",
    "max_episodes = 500\n",
    "\n",
    "params['problem'] = 'tsp'\n",
    "params['node_dimension'] = 2\n",
    "params['embedding_dimension'] = embedding_dimension\n",
    "params['max_nodes_per_graph'] = max_nodes_per_graph\n",
    "params['max_episode_length'] = max_nodes_per_graph + 1\n",
    "params['max_episodes'] = max_episodes\n",
    "params['batch_size'] = params['max_episode_length'] * rollouts_per_batch\n",
    "params['max_steps'] = params['max_episodes'] * params['max_episode_length'] * rollouts_per_batch\n",
    "params['epsilon_start'] = 1.0\n",
    "params['epsilon_finish'] = 0.01\n",
    "params['epsilon_anneal_time'] =  pct_epsilon_anneal_time * params['max_steps']\n",
    "params['entropy_weight'] = 0.1\n",
    "params['entropy_regularization'] = False\n",
    "params['lr'] = 0.006\n",
    "params['gamma'] = 0.99\n",
    "params['plot_frequency'] = 10\n",
    "\n",
    "\n",
    "# Create network\n",
    "basic_network = BasicNetwork(max_nodes_per_graph = params['max_nodes_per_graph'], node_dimension = params['node_dimension'], \n",
    "                             embedding_dimension = params['embedding_dimension'])\n",
    "\n",
    "# Create environment\n",
    "env = EnviornmentTSP(cities = cities, max_nodes_per_graph = params['max_nodes_per_graph'], node_dimension = params['node_dimension'])\n",
    "\n",
    "# Create learner \n",
    "controller = ActorCriticController(basic_network)\n",
    "learner = ReinforceLearner(model = basic_network, controller = controller, params = params)\n",
    "\n",
    "# Run experiment\n",
    "experiment = ActorCriticExperiment(params = params, model = basic_network, env = env, learner = learner)\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.plot_rollout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['advantage_bias'] = True\n",
    "params['value_targets'] = 'td'\n",
    "\n",
    "# Create network\n",
    "basic_network = BasicNetwork(max_nodes_per_graph = params['max_nodes_per_graph'], node_dimension = params['node_dimension'], \n",
    "                             embedding_dimension = params['embedding_dimension'])\n",
    "\n",
    "# Create environment\n",
    "env = EnviornmentTSP(cities = cities, max_nodes_per_graph = params['max_nodes_per_graph'], node_dimension = params['node_dimension'])\n",
    "\n",
    "# Create learner \n",
    "controller = ActorCriticController(basic_network)\n",
    "learner = BiasedReinforceLearner(model = basic_network, controller = controller, params = params)\n",
    "\n",
    "# Run experiment\n",
    "experiment = ActorCriticExperiment(params = params, model = basic_network, env = env, learner = learner)\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.plot_rollout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['offpolicy_iterations'] = 10\n",
    "\n",
    "# Create network\n",
    "basic_network = BasicNetwork(max_nodes_per_graph = params['max_nodes_per_graph'], node_dimension = params['node_dimension'], \n",
    "                             embedding_dimension = params['embedding_dimension'])\n",
    "\n",
    "# Create environment\n",
    "env = EnviornmentTSP(cities = cities, max_nodes_per_graph = params['max_nodes_per_graph'], node_dimension = params['node_dimension'])\n",
    "\n",
    "# Create learner \n",
    "controller = ActorCriticController(basic_network)\n",
    "learner = OffpolicyActorCriticLearner(model = basic_network, controller = controller, params = params)\n",
    "\n",
    "# Run experiment\n",
    "experiment = ActorCriticExperiment(params = params, model = basic_network, env = env, learner = learner)\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.plot_rollout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['offpolicy_iterations'] = 10\n",
    "\n",
    "# Create network\n",
    "basic_network = BasicNetwork(max_nodes_per_graph = params['max_nodes_per_graph'], node_dimension = params['node_dimension'], \n",
    "                             embedding_dimension = params['embedding_dimension'])\n",
    "\n",
    "# Create environment\n",
    "env = EnviornmentTSP(cities = cities, max_nodes_per_graph = params['max_nodes_per_graph'], node_dimension = params['node_dimension'])\n",
    "\n",
    "# Create learner \n",
    "controller = ActorCriticController(basic_network)\n",
    "learner = PPOLearner(model = basic_network, controller = controller, params = params)\n",
    "\n",
    "# Run experiment\n",
    "experiment = ActorCriticExperiment(params = params, model = basic_network, env = env, learner = learner)\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameters as trial suggestions\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    entropy_weight = trial.suggest_float('entropy_weight', 0, 1)\n",
    "    rollouts_in_batch = trial.suggest_int('rollouts_in_batch', 1, 100)\n",
    "    pct_epsilon_anneal_time = trial.suggest_float('pct_epsilon_anneal_time', 0.5, 1)\n",
    "    epsilon_start = trial.suggest_float('epsilon_start', 0, 1)\n",
    "    epsilon_finish = trial.suggest_float('epsilon_finish', 0, 1)\n",
    "    entropy_regularization = trial.suggest_categorical('entropy_regularization', [True, False])\n",
    "\n",
    "    # Use these parameters to create components\n",
    "    params['batch_size'] = (max_nodes_per_graph + 1) * rollouts_in_batch\n",
    "    params['max_steps'] = params['max_episodes'] * (max_nodes_per_graph + 1) * rollouts_in_batch\n",
    "    params['epsilon_start'] = epsilon_start\n",
    "    params['epsilon_finish'] = epsilon_finish\n",
    "    params['epsilon_anneal_time'] = pct_epsilon_anneal_time * params['max_steps']\n",
    "    params['entropy_regularization'] = entropy_regularization\n",
    "    params['entropy_weight'] = entropy_weight\n",
    "    params['lr'] = lr\n",
    "    params['plot_frequency'] = None\n",
    "\n",
    "\n",
    "    basic_network = BasicNetwork(max_nodes_per_graph=params['max_nodes_per_graph'], \n",
    "                                 node_dimension=params['node_dimension'], \n",
    "                                 embedding_dimension=params['embedding_dimension'])\n",
    "    env = EnviornmentTSP(cities=cities, max_nodes_per_graph=params['max_nodes_per_graph'], \n",
    "                         node_dimension=params['node_dimension'])\n",
    "    controller = ActorCriticController(basic_network)\n",
    "    learner = ReinforceLearner(model=basic_network, controller=controller, params=params)\n",
    "    experiment = ActorCriticExperiment(params=params, model=basic_network, env=env, learner=learner)\n",
    "\n",
    "    # Perform training and return the evaluation metric\n",
    "    final_metric = experiment.run()  # Assume `run` returns a performance indicator\n",
    "    return final_metric\n",
    "\n",
    "study = optuna.create_study(direction='maximize')  # or 'minimize' if you're minimizing a metric\n",
    "study.optimize(objective, n_trials=25)  # You can adjust the number of trials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
