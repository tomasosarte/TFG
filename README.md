
# Search & Analysis of New Heuristics for Solving NP-Hard Problems with Deep Reinforcement Learning

## Author: Tomàs Osarte Segura
### Thesis Supervisor: Sergio Álvarez Napagao

## Overview

This repository contains the materials related to the bachelor's thesis titled **"Search & Analysis of New Heuristics for Solving NP-Hard Problems with Deep Reinforcement Learning"**. This work was submitted to the Facultat d'Informàtica de Barcelona (FIB) at the Universitat Politècnica de Catalunya (UPC) - BarcelonaTech.

### Abstract

In recent years, Deep Reinforcement Learning (DRL) has emerged as a promising avenue for devising heuristic solutions to NP-Hard (NPH) problems, which are notoriously difficult computational puzzles. Unlike traditional approaches, DRL leverages the power of Machine Learning (ML) to autonomously learn and adapt strategies through interaction with the problem environment. While demonstrating notable advantages over conventional methods, the full potential of DRL remains largely untapped, with many aspects of its application and effectiveness yet to be fully explored.

This thesis endeavors to delve deeper into the realm of DRL, aiming to identify and address these limitations by critically examining various aspects of DRL techniques and exploring novel approaches. Through a systematic analysis and experimentation within DRL frameworks, this research aims to uncover new insights and innovative solutions to mitigate the limitations inherent in current approaches, thereby contributing to the ongoing advancement of DRL methodologies and fostering broader adoption for solving NP-Hard problems.

### Contents

- **Chapter 1: Introduction**
  - Contextualization
  - Problem Description
  - Actors Involved
  - Scope
  - Justification
  - Methodology

- **Chapter 2: Background**
  - Computational Complexity
  - NP-Hard Problems
  - Reinforcement Learning
  - Deep Learning

- **Chapter 3: State of the Art**
  - Pointer Networks
  - Transformer
  - Attention to Solve Routing Problems
  - Alpha Zero Approach

- **Chapter 4: Proposal: Versatile DRL Framework**
  - Environments
  - Runners
  - Models
  - Controllers
  - Learners
  - Experiments

- **Chapter 5: State Representation**

- **Chapter 6: Networks**
  - Simple Decoder
  - Attention Encoder-Decoder

- **Chapter 7: Experimental Results**
  - Single Instance Training
  - Single Size Training
  - General Training

- **Chapter 8: Conclusions**
  - Requirements Review
  - Objectives Review
  - Future Research

- **Appendices**
  - Project Planning
  - Economic Management and Sustainability

## Code

The code corresponding to this thesis is located in the `tfg` folder. This folder contains all the necessary scripts and tools used for the implementation and experimentation phases discussed in the thesis.

## Acknowledgements

I am immensely grateful to Sergio Álvarez, my principal advisor, for his unwavering support and invaluable guidance throughout the research, development, and writing phases of this bachelor thesis. His expertise and insights have not only shaped this project but have also profoundly enhanced my own learning and understanding.

I extend my heartfelt thanks to Manuel Romero, who played a crucial role as an additional helper during both the development and training stages of this work. His assistance was instrumental in overcoming numerous challenges, and his enthusiasm was a constant source of motivation.
